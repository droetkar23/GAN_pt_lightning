model_parameters:
  l1_lambda: 100
  lr: 2.0e-4

dataset_parameters:
  batch_size: 16
  data_dir: ""
  num_workers: 3
  train_ds_size: 0.1
  val_ds_size: 0.1

trainer_parameters:
  max_epochs: 10
  accelerator: gpu
  devices: [0]