model_parameters:
  l1_lambda: 100
  lr: 2.0e-4

dataset_parameters:
  batch_size: 16
  data_dir: ""
  num_workers: 3
  train_ds_size: 0.3
  val_ds_size: 0.3

trainer_parameters:
  max_epochs: 20
  accelerator: gpu
  devices: [0]